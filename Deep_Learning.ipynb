{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61331ca8",
   "metadata": {},
   "source": [
    "# Séance du Mardi 05/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcdf438",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416ebe1",
   "metadata": {},
   "source": [
    "Deep Learning ou apprentissage profond. Le deep learning permet de faire le traitement du langage naturel via:\n",
    "\n",
    "  - le NLP(Natural Language Processing) et \n",
    "  \n",
    "  \n",
    "  - le traitement d'images ou de vidéos à travers la computer vision(vision par ordinateur). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e4c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df612a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,3,8,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0ab004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  8, 17])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4786dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1,2,3,8,17], [11,22,31,83,17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194e6746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  8, 17],\n",
       "       [11, 22, 31, 83, 17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.array(([[1,2,3,8,17], [11,22,31,83,17]], [[15,21,83,8,17], [14,22,31,63,97]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68384a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  8, 17],\n",
       "        [11, 22, 31, 83, 17]],\n",
       "\n",
       "       [[15, 21, 83,  8, 17],\n",
       "        [14, 22, 31, 63, 97]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837399c",
   "metadata": {},
   "source": [
    "#### Une matrice est un ensemble de vecteurs \n",
    "#### Un tensor est un ensemble de matrices\n",
    "\n",
    "- Lorsqu'une image est en blanc-noir, elle est en deux dimensions(longueur et largeur) mais lorsqu'elle est en couleur, elle est en trois dimensions doncplus la hauteur qui permet de gérer la couleur.\n",
    "\n",
    "\n",
    "- Un modèle de deep learning est constitué de layers(couches).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e690e9a",
   "metadata": {},
   "source": [
    "#### Variables/Paramètres\n",
    "\n",
    "x: Input ou entrée\n",
    "\n",
    "w: Poids attribué à chaque entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6825e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dans le cas de trois inputs\n",
    "w1.x1  + w2.x2  + w3.x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f7fac",
   "metadata": {},
   "source": [
    "  - La fonction d'activation vous permet de calculer normalement la sortie/output.\n",
    "    \n",
    "    \n",
    "  - L'output de la couche précédente est l'input de la couche qui suit cette dernière.\n",
    "\n",
    "\n",
    "On a aussi la notion de hidden layers qui représente les couches cachées c'est-à-dire les couches entre la première et la dernière. La fonction d'activation se trouve au niveau de la toute dernière couche. Une autre fonction appelée fonction coût ou fonction de perte pour calculer l'erreur de prédiction. \n",
    "\n",
    "#### Notion de back propagation: \n",
    "\n",
    "Sur la base de la valeur de l'erreur, on actualise les valeurs de poids attribués à chaque variable et on performe encore le modèle. Lorsqu'on ajuste les poids et l'erreur est plus petite, on continue dans ce sens. Dans le cas contraire, on ajuste autrement.\n",
    "\n",
    "Lorsqu'on essaie de calculer les erreurs de prédiction d'un modèle, on peut utiliser la fonction de la descente de gradient afin de trouver la plus petite erreur possible. \n",
    "\n",
    "La même chose se passe ici. On compare les prédictions du modèle par rapport aux données originales afin de conserver les variations et trouver la plus petite valeur possible.\n",
    "\n",
    "Nous avons autant de noeuds au niveau de la première couche que de variables. Ce qui n'est pas forcément le cas au niveau des couches cachées.\n",
    "\n",
    "#### Réseaux de neurones:\n",
    "\n",
    "Les poids sont générés de manière aléatoire. Les inputs sont envoyés au niveau de la première couche. Il y a une combinaison entre les inputs et les poids aléatoires (avec un biais à chaque combinaison linéaire). L'output sera envoyé à la couche suivante. Pour obtenir une sortie, il y a des combinaisons linéaires(possible d'avoir des fonctions d'activation au niveau des couches cachées dans certaines architectures). La fonction d'activation est appliquée à la dernière couche(sur la combnaison linéaire obtenue à ce niveau) pour obtenir la prédiction. La fonction loss est ensuite appliquée pour calculer l'erreur de prédiction (loss_score). Après ça, il y a l'optimizer qui est responsable du sens que la descente de gradient va prendre. Il permet de savoir si le minimum est déjà atteint ou pas. \n",
    "\n",
    "Il faut toujours aller dans le sens opposé du gradient. Si le gradient est positif, il faut aller dans le sens inverse dans l'ajustement. Lorsqu'il est négatif, c'est que vous êtes sur le bon chemin.\n",
    "\n",
    "Les poids liés à la plus petite erreur permettent donc de constituer notre modèle. On obtient donc des valeurs fixes des poids à la fin du processus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d26026",
   "metadata": {},
   "source": [
    "#### Les notions d'epoch et de batch. \n",
    "\n",
    "- Batch: On donne au modèle un ensemble de lots pour qu'après ce nombre, le modèle montre ses performances et son bilan.\n",
    "    \n",
    "    - Epoch: Chaque fois que le modèle finit un batch\n",
    "        \n",
    "      - Taille de l'échantillon: Valeur du batch*Nbre d'epoch (Dans le cas où les valeurs de batch sont identiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdfaf6e",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "\n",
    "Les données de validation font partie des données d'entraînement. \n",
    "\n",
    "Lorsqu'on a 4 batch, on prend 3 pour faire la validation et on change ainsi de suite pour faire passer tous les batch: c'est cette opération qui s'appelle la validation.\n",
    "\n",
    "Ensuite, on applique le modèle sur les données du test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660c8fb",
   "metadata": {},
   "source": [
    "## Fonctions d'activation\n",
    "\n",
    "Il y a principalement 05 fonctions d'activation. La plus utilisée est la fonction sigmoïd.\n",
    "\n",
    "- Sigmoïd: Pour une tâche de classification binaire(sortie entre 0 et 1). Dans ce cas, lorsque la valeur de la probabilité est inférieure à 0.5 ça s'approxime de 0 et lorsque la valeur est supérieure à 0.5 ça s'approxime de 1. Elle provient de la famille des fonctions softmax. \n",
    "\n",
    "- softmax: Lorsque la classification est multi-classe.\n",
    "\n",
    "- relu: Utilisée au niveau des couches cachées.\n",
    "\n",
    "- tan: Utilisée au niveau des couches cachées avec une sortie entre -1 et 1.\n",
    "\n",
    "- Identité: Utilisée au niveau de la couche de sortie lorsqu'il s'agit de la régression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c8f68",
   "metadata": {},
   "source": [
    "sigmoid(x) = 1/(1+exp(-x)) ou softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4743d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(xi)/sum(exp(-xi)), 0...n-1 #softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu(x) = max(0,x) #relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e21ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = x si x>0 et alpha.x sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba701e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tan(x) = exp(x)-exp(-x)/exp(x)+exp(-x) #tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = x #Identité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e6d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivee(f,x, alpha = 0.00001):\n",
    "    return round((f(x+alpha)-f(x))/alpha,4)#alpha peut être égal à 0.00001 ou autre.\n",
    "\n",
    "#au lieu du round, on peut aussi utiliser np.trunc() pour réduire\n",
    "#le nombre de chiffres après la virgule mais à un chiffre seulement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f08cd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : x**2\n",
    "\n",
    "#def function(x):\n",
    "#return 2*x**3-6*x+8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "976c8f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivee(f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "101fc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd42065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaccc3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivee(sigmoid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(-x)/(1+exp(-x)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c105f",
   "metadata": {},
   "source": [
    "## Notion d'entropie\n",
    "\n",
    "L'entropie est utilisée dans plusieurs domaines comme la thermodynamique et autres. C'est pour gérer l'incertitude ou le désordre en termes de classification. Elle permet de mesurer le degré d'incertitude sur la valeur que prendra la variable aléatoire.\n",
    "\n",
    "Plus l'entropie est élevée, plus l'incertitude associée à la valeur de la variable aléatoire est élevée. La valeur de la variable aléatoire est difficile à prédire. \n",
    "\n",
    "L'idée c'est donc de minimiser la valeur de l'entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9912c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bec27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
